---
layout: post
title: 由浅入深搞定最大熵模型
categories: [机器学习]
tags: MaximumEntropyModel
---

### Index
<!-- TOC -->
- [背景](#背景)
<!-- /TOC -->

---
## 背景
有这么几个概念，你懂不？
- 自信息(Self-information)
- 熵
- 联合熵(Joint Entropy)
- 条件熵(Conditional Entropy)
- 相对熵(Relative Entropy，也称为KL散度，Kullback–Leibler divergence)
- 交叉熵(Cross entropy)
懂了你就跳过去，不懂咱就先讲讲，最大熵原理和模型最后再说

## 关于熵的几个概念
### 自信息(Self-information)
### 熵
### 联合熵(Joint Entropy)
### 条件熵(Conditional Entropy)
### 相对熵(Relative Entropy，也称为KL散度，Kullback–Leibler divergence)
### 交叉熵(Cross entropy)

## 最大熵原理

## 最大熵模型

---
# 相关引用
1. [详解机器学习中的熵、条件熵、相对熵和交叉熵](https://www.cnblogs.com/kyrieng/p/8694705.html)
2. [一步一步理解最大熵模型](https://www.cnblogs.com/wxquare/p/5858008.html)