---
layout: post
title: 由浅入深搞定最大熵模型
categories: [Machine Learning]
tags: MaximumEntropyModel
---

### Index
<!-- TOC -->
- [背景](#背景)
- [关于熵的几个概念](#关于熵的几个概念)
- [最大熵原理](#最大熵原理)
- [最大熵模型](#最大熵模型)
<!-- /TOC -->

---
## 背景
有这么几个概念，你懂不？
- 自信息(Self-information)
- 熵
- 联合熵(Joint Entropy)
- 条件熵(Conditional Entropy)
- 相对熵(Relative Entropy，也称为KL散度，Kullback–Leibler divergence)
- 交叉熵(Cross entropy)

懂了你就跳过去，不懂咱就先讲讲，最大熵原理和模型最后再说。

## 关于熵的几个概念
### 自信息(Self-information)
### 熵(Entropy)
### 联合熵(Joint Entropy)
### 条件熵(Conditional Entropy)
### 相对熵(Relative Entropy，也称为KL散度，Kullback–Leibler divergence)
### 交叉熵(Cross entropy)

## 最大熵原理

## 最大熵模型

---
# 相关引用
1. [详解机器学习中的熵、条件熵、相对熵和交叉熵](https://www.cnblogs.com/kyrieng/p/8694705.html)
2. [一步一步理解最大熵模型](https://www.cnblogs.com/wxquare/p/5858008.html)
3. [相对熵-百度百科](https://baike.baidu.com/item/%E7%9B%B8%E5%AF%B9%E7%86%B5/4233536?fr=aladdin)