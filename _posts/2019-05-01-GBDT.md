---
layout: post
title: GBDT家族
categories: [Machine Learning]
tags: XGBoost 
---

## 背景

GBDT (Gradient Boosting Decision Tree) 是机器学习中一个长盛不衰的模型，其主要思想是利用弱分类器（决策树）迭代训练以得到最优模型，该模型具有训练效果好、不易过拟合等优点。GBDT 在工业界应用广泛，通常被用于点击率预测，搜索排序等任务。GBDT 也是各种数据挖掘竞赛的致命武器，据统计 Kaggle 上的比赛有一半以上的冠军方案都是基于 GBDT。 

## Boosting思想

不同的objective和最小化其的方法决定了不同种类的Boosting:

![boosting-objective](/assets/images/blog/gbdt/boosting-objective.jpg)
GBDT其实就是上图中的Gradient Boosting的一个子类（弱分类器为决策树）


## GBDT基础模型

基本上所有的机器学习模型都是下面公式演化而来

$$
\begin{equation}
   \widehat{y_i} = \sum_{i=1}^d w_j x_{ij}
\end{equation}
$$
上述公式中$x_0=1$，就是引入了一个偏差量，或者说加入了一个常数项。由该公式可以演化一些模型：
- 线性模型，最后的得分就是$\widehat{y_i}$
- logistic模型，最后的得分是$\frac{1}{exp(-\widehat{y_i})}$，然后设定阈值，转为正负样本
- 其他的大部分模型，都在基于$\widehat{y_i}$做文章，转化为最后的分数

---
# 相关引用
1. [GBDT的小结](https://blog.csdn.net/niuniuyuh/article/details/76922210)
2. [Friedman: GREEDY FUNCTION APPROXIMATION:A GRADIENT BOOSTING MACHINE](https://projecteuclid.org/download/pdf_1/euclid.aos/1013203451)
3. [GBDT简单理解](https://blog.csdn.net/meanme/article/details/50914222)